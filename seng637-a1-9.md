> **SENG 637 - Software Testing, Reliability, and Quality**

**Lab. Report \#1 â€“ Introduction to Testing and Defect Tracking**

| Group: 9 |
| -------- |
| Maheen   |
| Dipu     |
| Jasdeep  |
| Dhruvi   |

**Table of Contents**

[1 Introduction](#1-introduction)

[2 High-level description of the exploratory testing plan](#2-high-level-description-of-the-exploratory-testing-plan)

[3 Comparative Evaluation of Exploratory and Manual Functional Testing](#3-comparative-evaluation-of-exploratory-and-manual-functional-testing)

[4 Notes and discussion of the peer reviews of defect reports](#4-notes-and-discussion-of-the-peer-reviews-of-defect-reports)

[5 How the pair testing was managed and teamwork/effort was divided](#5-how-the-pair-testing-was-managed-and-teamworkeffort-was-divided)

[6 Challenges overcome, and lessons learned](#6-challenges-overcome-and-lessons-learned)

[7 Comments/feedback on the lab and lab document itself](#7-comments-and-feedback-on-the-lab-and-lab-document-itself)

# 1 Introduction

In this report, a Java-based Automated Teller Machine (ATM) simulation system is systematically evaluated using standard software testing and defect tracking procedures. Two consecutive software releases (versions 1.0 and 1.1) make up the system under test (SUT), enabling evaluation of fault handling and functional correctness.

The ATM's fundamental operational and transactional behaviours, such as system startup and shutdown, session control, cash withdrawals, deposits, account transfers, balance inquiries, and error handling under unusual circumstances, were the focus of testing activities. Complementary testing techniques were used in combination. The purpose of exploratory testing was to identify flaws relating to edge cases, invalid inputs, and state transitions, as well as to analyze how the system behaved in unscripted interactions. To confirm compliance with documented functional requirements, manual scripted testing was then implemented using a predetermined test suite. On version 1.1, regression testing assessed how well previously reported flaws were fixed and found any regressions brought about by system changes.

Using Jira, all found flaws were noted, monitored, and updated in accordance with standard defect reporting and lifecycle management procedures. Expected behaviour, test coverage, and defect validation were based on the published system requirements and the assignment specification.

---

# 2 High-Level Description of the Exploratory Testing Plan

In order to identify functional flaws, unexpected behaviours, and risky areas before structured validation, the exploratory testing phase was created as an initial, discovery-driven assessment of the ATM simulation system. In order to direct later testing activities, this phase placed a strong emphasis on early risk assessment, informed defect discovery, and quick learning of system behaviour.

The team purposefully positioned exploratory testing as a supplement to manual scripted testing, enabling them to observe how the system behaved under various and imperfect user interactions and to probe system behaviour beyond predetermined requirements.

## Test Approach

Exploratory testing was conducted using a pair-testing model to maximize coverage, defect detection, and shared system understanding within a limited execution window. The team was divided into two pairs, each assigned responsibility for distinct functional areas, enabling parallel exploration and minimizing redundant effort.

To set baseline expectations for proper system behaviour, testers went over the high-level functional requirements listed in Appendix B of the assignment instructions before execution. The "System Under Test" and "Familiarization with the ATM System" sections of the assignment documentation provided additional guidance to guarantee alignment with intended operational flows because of the limited scope and simulated nature of the ATM system.

This phase focused on core functionalities and representative corner cases, purposefully prioritizing breadth over depth in order to avoid attempting exhaustive validation. By delaying thorough requirement verification until the manual scripted testing stage, this trade-off allowed for the quick discovery of flaws and behavioural irregularities. Because exploratory testing is by its very nature unscripted and adaptable, coverage choices were continuously improved by taking into account new risk areas and system responses.

## Pair Assignment and Functional Focus

Two exploratory testing pairs were formed with clearly defined functional ownership:

- **Pair 1 (Maheen & Dipu)** focused on system startup and shutdown behaviour, session handling (including card insertion and PIN validation), and deposit-related functionality.

- **Pair 2 (Jasdeep & Dhruvi)** focused on withdrawal operations, inter-account fund transfers, and balance inquiry functionality.

This functional partitioning allowed independent subsystems to be explored concurrently while maintaining accountability for coverage and defect reporting within each functional area.

## Test Strategy

Exploratory testing was guided by a set of complementary strategies intended to expose both nominal and adverse system behaviour:

- **Common-Path Testing**  
Baseline for anticipated system performance through the validation of common user workflows involving legitimate credentials and successful transactions.

- **Boundary Testing**  
  Analysis of system behaviour at operational boundaries, such as minimum deposit amounts, withdrawal restrictions, and account balance thresholds, where flaws are frequently noticed.

- **Exception-Path Testing**  
   Evaluating robustness and error handling, purposefully set up error conditions like invalid PIN entries, insufficient account balances, unreadable cards, and transaction cancellations.

- **State-Transition Testing**  
  Verification of correct behaviour across system state changes, including power on/off transitions, session initiation and termination, and transaction flow progression.

These strategies ensured that exploratory testing addressed both functional correctness and system resilience.

## Test Case Generation

Test scenarios were dynamically generated using the following criteria:

- Functional requirements specified in Appendix B
- Expected behaviour informed by standard ATM usage patterns
- Anticipated failure modes and edge-case conditions observed during testing

Scenario generation remained intentionally flexible, allowing testers to adapt in real-time as new behaviours, defects, or inconsistencies were identified.

## Documentation Approach

Every testing pair kept real-time records of scenarios that were carried out, system outputs that were observed, and defects that were found. Flaw had a detailed reproduction process, a clear description of the expected and actual results, a severity classification, and references to the functionality of the impacted system.

This documentation-first approach ensured that exploratory findings could be reliably reproduced, reviewed, and retested during later testing phases.

## Outcome of the Exploratory Testing Phase

This exploratory testing plan made it possible to find bugs early on that predefined test cases might not have covered, especially those that had to do with edge cases, error handling, and state transitions. Knowledge gained during this phase helped with later manual scripted testing and regression testing, which made the validation of the ABM simulation system more focused and useful.

---

# 3 Comparative Evaluation of Exploratory and Manual Functional Testing

Exploratory testing and manual functional (scripted) testing were employed as complementary validation strategies to assess the correctness, robustness, and behavioural consistency of the ATM simulation system. Although both approaches aim to identify defects, they operate under fundamentally different testing paradigms and therefore expose distinct classes of faults. This section presents a comparative evaluation grounded in empirical observations from testing activities conducted on versions 1.0 and 1.1 of the system.
## Methodological Comparison

| Dimension              | Exploratory Testing                                                                  | Manual Functional (Scripted) Testing                                              |
| ---------------------- | ------------------------------------------------------------------------------------ | --------------------------------------------------------------------------------- |
| Primary Intent         | Early-stage defect discovery and behavioral risk identification                      | Formal verification of conformance to documented requirements                     |
| Control Structure      | Tester-driven, adaptive exploration guided by observed system behavior               | Deterministic execution governed by predefined test cases                         |
| Planning Overhead      | Minimal upfront planning; emphasis on real-time reasoning                            | Significant upfront specification of inputs, steps, and expected outputs          |
| Coverage Dynamics      | Broad, non-uniform coverage across features and system states                        | Structured, requirement-aligned coverage of specified scenarios                   |
| Defect Characteristics | State-transition faults, boundary-condition failures, error-handling inconsistencies | Functional deviations, incorrect outputs, and missing requirement implementations |
| Repeatability          | Lower unless supported by disciplined documentation                                  | High, due to standardized execution and clearly defined oracles                   |
| Tester Dependence      | High; effectiveness strongly correlated with tester expertise                        | Moderate; process-driven execution reduces individual variability                 |
| Role in Regression     | Limited applicability                                                                | Central to regression verification                                                |

Within the context of this project, exploratory testing proved particularly effective at exposing defects related to exception handling, cancellation paths, and transitions between operational states. Its adaptive nature enabled testers to pursue anomalous system responses and investigate behaviours not explicitly anticipated in the predefined test suite. As a result, exploratory testing contributed significantly to early defect discovery and risk identification.

On the other hand, manual functional testing offered a thorough and reliable method of confirming that the system meets the functional requirements. Transaction processing, session management, and error handling scenarios specifically outlined in the requirements were consistently verified through execution of the predefined test suite.

From an efficiency perspective, manual functional testing required more preparation work but produced a stronger guarantee of requirement compliance and behavioural stability, whereas exploratory testing produced high early value with comparatively low setup costs. Both strategies offered a deeper understanding of system behaviour and wider defect coverage than either strategy could accomplish alone.

---

# 4 Notes and Discussion of the Peer Reviews of Defect Reports

To enhance report quality, consistency, and reproducibility, a structured peer review of all defect reports was carried out following the conclusion of the exploratory and manual scripted testing phases. In order to guarantee that all defects entering the verification phase complied with a consistent standard of documentation and severity classification, the peer review process was purposefully carried out prior to regression testing.

Each testing pair independently reviewed the defect reports authored by the other pair using the defect tracking system. The review focused on evaluating report quality rather than rediscovering defects. The reviewers evaluated the reproduction steps for completeness and clarity while assessing the expected outcomes and actual outcomes for correctness and precision. The reviewers assessed the severity and priority assignments for appropriateness, checked version tagging accuracy between v1.0 and v1.1 and verified compliance with assignment reporting guidelines.

The peer review process discovered multiple common errors which occur during the initial defect reporting process. The reports needed additional development because their reproduction steps contained unclear information that needed to be fixed. The team changed severity classifications in a few instances to match actual defect effects on system functions instead of using defect occurrence rates. The testing team found two separate defect reports which contained identical problems that different teams discovered during their exploratory testing.

The defect repository received its first round of corrective actions when peer feedback showed the need for specific changes. The team established links between duplicate and overlapping defects to improve their understanding while developing testing procedures with supporting documentation that needed additional explanation, and they modified severity ratings to establish better uniformity throughout the entire defect collection. The team created more understandable defect reports which contained specific actions that testers could repeat during their regression testing process.

The peer review process brought major improvements to the quality and maintainability of the defect repository. The system achieved defect classification consistency while dedicated resources worked to create reproducible results, and the team developed a shared understanding of defect impact.

---

# 5 How the Pair Testing Was Managed and Teamwork/Effort Was Divided

The testing process used pair testing because it served as the main method for testing teams to work together, which helped improve their ability to find defects and their understanding of system operations. The team assigned duties in a way that would enable them to complete work efficiently while maintaining high standards for both analysis and report creation.


## Pair Testing Structure and Role Allocation

The testing team conducted exploratory testing according to their established plan, which required them to divide their members into two groups who would work on different areas. The team established specific responsibilities for each member of the pair, which they enforced throughout their work period.

- **Driver (Test Executor):** Responsible for interacting directly with the system under test, executing test scenarios, and navigating transaction workflows.
- **Observer (Reviewer/Recorder):** Responsible for monitoring system behaviour, identifying deviations from expected outcomes, validating results, and documenting defects in the defect tracking system.

The team implemented role rotation between pairs to maintain equal work distribution while preventing team member exhaustion and enabling members to learn both execution skills and analytical assessment skills. The rotation process enabled the team to discover defects which would have remained hidden to those who worked in only one role.

## Coordination and Communication

The testing sessions included brief synchronization meetings, which allowed the two pairs to maintain their coordination. The team used these sessions to define functional coverage limits and to exchange their observations of system failures while they worked to reduce duplicate testing of identical system elements. The team used assignment specifications together with system requirements to build a standardized system behaviour interpretation, which they could defend to outside parties when system behaviour became unclear.

This structured communication ensured alignment across pairs while preserving independent exploration during testing execution.

## Manual Scripted and Regression Testing Collaboration

The testing team switched from pair-based testing to a new testing approach, which enabled all testers to work together. The team members received their test execution and defect documentation and test progression coordination duties through a system which assigned and rotated these responsibilities. The testing method guaranteed complete implementation of the test suite and maintained reporting standards while the team members shared responsibility for testing coverage.

The team conducted regression testing by distributing known defects and test cases to individual members who tested version 1.1 of the system. They retested defects that had been assigned to them and updated the status of those defects by recording their results in the tracking system. The team reviewed all newly found defects to determine their classification before reporting because they needed to confirm that these defects had not been discovered previously.

---

# 6 Challenges Overcome and Lessons Learned

The testing process identified multiple technical issues and process deficiencies which needed to be fixed through specific solutions to ensure testing integrity, performance and testing results. The testing team used structured mitigation strategies to resolve these problems because they considered them to be major challenges which needed to be solved through organized approaches that would enhance both testing processes and their outcomes. The challenges encountered and the corresponding lessons learned are summarized below.

## Key Challenges and Mitigation

- **Ambiguity in expected system behaviour** for exceptional scenarios (e.g., transaction cancellations, invalid input handling, and state transitions) due to implicit or underspecified requirements.  
  **Mitigation:** A shared interpretation framework was established through repeated reference to the assignment specification and use case documentation, ensuring consistent decision-making across testers.

- **Inconsistent defect severity and priority classification** during early testing stages, particularly for defects affecting usability versus core transactional correctness.  
  **Mitigation:** Structured peer review and calibration discussions were used to align severity definitions and improve consistency across the defect repository.

- **Coverage and time management challenges** inherent to exploratory testing; unlimited exploration leads to disproportionate emphasis on isolated behaviours.
  **Mitigation:** Functional partitioning between testing pairs and continuous awareness of coverage boundaries helped maintain balanced exploration.

- **Risk of fragmented system understanding** when defects were discovered independently by different testers.  
  **Mitigation:** Pair testing, real-time discussion, and post-session synchronization ensured shared understanding and reduced individual bias.

## Lessons Learned

- The combination of exploratory testing and scripted testing creates dual advantages because it permits fast detection of unexpected system behaviour while also verifying all requirements.
- Effective regression testing and accurate defect verification depend on proper defect documentation, which serves as the essential foundation. 
- Severity classification requires alignment between different criteria because shared standards help with both defence and prioritization. 
- The use of structured collaboration systems through pair testing, peer review, and role rotation methods improves both the success of defect detection and the accuracy of reporting. 
- Process discipline scales quality, particularly in multi-phase testing workflows involving regression validation.

---

# 7 Comments and Feedback on the Lab and Lab Document Itself

The laboratory established an organized framework which effectively demonstrated software testing methods and defect tracking techniques. The combination of exploratory testing, manual scripted testing and regression testing demonstrated authentic testing practices while showing that multiple testing methods are necessary to achieve complete testing results.

The lab documentation maintained its clarity throughout its logical structure, which showed particular strength in the comprehensive system description, usage scenarios and standard testing procedures. The testing activities received effective planning and execution support through these components, which served as essential elements for their execution. The assignment gained more authentic work experience through the requirement to use an industry-standard defect tracking tool.

One area for potential improvement is the clarification of expected behaviour for certain exceptional scenarios, such as transaction cancellation flows and edge-case handling. The testing teams will achieve a better understanding through extra guidance and specific examples, which will decrease the existing ambiguity. The test suite requires better usability through the resolution of the minor test case numbering discrepancies which were found in the testing process.

The lab work proved useful despite minor problems because it helped students learn software testing methods, defect reporting techniques and collaborative testing methods. The assignment combined technical complexity and real-world usability to create an effective introduction to systematic software quality assurance practices.
